Device: cpu
{'env': 'CartPole-v0', 'numdiscreteactions': 8, 'double': True, 'per': True, 'dueling': True, 'rnd': False, 'multistep': None, 'gamma': 0.99, 'alpha': 0.0005, 'alpha_decay_every': 2000, 'alphadecay': 0.95, 'alpha_rnd': 0.001, 'epsilon': 1.0, 'epsilondecay': 0.99, 'minepsilon': 0.2, 'buffersize': 100000, 'batchsize': 128, 'train': True, 'hiddensize': 100, 'activation': 'tanh', 'numseeds': 3, 'numepisodes': 12000, 'numtestepisodes': 100, 'numsteps': 500, 'fititerations': 1, 'update_Qt_after': 20, 'opponent': 'weak', 'curriculum': False, 'save': True, 'savepath': '../saved/', 'savenum': 7, 'test': True, 'testfilename': None, 'plot': True, 'plotpath': '../plots/', 'verbose': False}
/Users/surabhisnath/opt/anaconda3/envs/RL_course/lib/python3.12/site-packages/gymnasium/envs/registration.py:517: DeprecationWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.deprecation(
Config for seed 0:
1.0
Starting seed 1
/Users/surabhisnath/Nextcloud/Documents/PhD/Courses/RL/RL_project/scripts/agent.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  Qtval = self.Qt.doubleQt(s_, torch.tensor(actions_to_use, device=device)).cpu().numpy()
/Users/surabhisnath/Nextcloud/Documents/PhD/Courses/RL/RL_project/scripts/Qfunction.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  weights = torch.tensor(weights, device=device, dtype=torch.float32)
Seed: 0. 600 episodes completed: Mean cumulative reward: 13.628333333333334
Seed: 0. 1200 episodes completed: Mean cumulative reward: 11.203333333333333
Seed: 0. 1800 episodes completed: Mean cumulative reward: 57.78
Seed: 0. 2400 episodes completed: Mean cumulative reward: 52.778333333333336
Seed: 0. 3000 episodes completed: Mean cumulative reward: 44.85166666666667
Seed: 0. 3600 episodes completed: Mean cumulative reward: 42.39666666666667
Seed: 0. 4200 episodes completed: Mean cumulative reward: 53.04666666666667
Seed: 0. 4800 episodes completed: Mean cumulative reward: 57.66166666666667
Seed: 0. 5400 episodes completed: Mean cumulative reward: 64.42333333333333
Seed: 0. 6000 episodes completed: Mean cumulative reward: 143.79
Seed: 0. 6600 episodes completed: Mean cumulative reward: 118.92333333333333
Seed: 0. 7200 episodes completed: Mean cumulative reward: 196.46166666666667
Seed: 0. 7800 episodes completed: Mean cumulative reward: 283.28
Seed: 0. 8400 episodes completed: Mean cumulative reward: 438.675
Seed: 0. 9000 episodes completed: Mean cumulative reward: 442.15166666666664
Seed: 0. 9600 episodes completed: Mean cumulative reward: 457.555
Seed: 0. 10200 episodes completed: Mean cumulative reward: 451.0783333333333
Seed: 0. 10800 episodes completed: Mean cumulative reward: 468.245
Seed: 0. 11400 episodes completed: Mean cumulative reward: 439.64666666666665
Seed: 0. 12000 episodes completed: Mean cumulative reward: 458.2816666666667
/Users/surabhisnath/opt/anaconda3/envs/RL_course/lib/python3.12/site-packages/gymnasium/envs/registration.py:517: DeprecationWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.deprecation(
Mean test reward 500.0 +/- std 0.0
Config for seed 100:
1.0
Starting seed 101
Seed: 100. 600 episodes completed: Mean cumulative reward: 12.953333333333333
Seed: 100. 1200 episodes completed: Mean cumulative reward: 10.875
Seed: 100. 1800 episodes completed: Mean cumulative reward: 10.743333333333334
Seed: 100. 2400 episodes completed: Mean cumulative reward: 11.438333333333333
Seed: 100. 3000 episodes completed: Mean cumulative reward: 57.583333333333336
Seed: 100. 3600 episodes completed: Mean cumulative reward: 49.19166666666667
Seed: 100. 4200 episodes completed: Mean cumulative reward: 34.51833333333333
Seed: 100. 4800 episodes completed: Mean cumulative reward: 48.61
Seed: 100. 5400 episodes completed: Mean cumulative reward: 55.153333333333336
Seed: 100. 6000 episodes completed: Mean cumulative reward: 74.865
Seed: 100. 6600 episodes completed: Mean cumulative reward: 71.355
Seed: 100. 7200 episodes completed: Mean cumulative reward: 94.08
Seed: 100. 7800 episodes completed: Mean cumulative reward: 116.98833333333333
Seed: 100. 8400 episodes completed: Mean cumulative reward: 123.675
Seed: 100. 9000 episodes completed: Mean cumulative reward: 166.14
Seed: 100. 9600 episodes completed: Mean cumulative reward: 352.49333333333334
Seed: 100. 10200 episodes completed: Mean cumulative reward: 420.3983333333333
Seed: 100. 10800 episodes completed: Mean cumulative reward: 475.04
Seed: 100. 11400 episodes completed: Mean cumulative reward: 485.87833333333333
Seed: 100. 12000 episodes completed: Mean cumulative reward: 488.335
Mean test reward 500.0 +/- std 0.0
Config for seed 200:
1.0
Starting seed 201
Seed: 200. 600 episodes completed: Mean cumulative reward: 18.983333333333334
Seed: 200. 1200 episodes completed: Mean cumulative reward: 14.603333333333333
Seed: 200. 1800 episodes completed: Mean cumulative reward: 15.873333333333333
Seed: 200. 2400 episodes completed: Mean cumulative reward: 17.286666666666665
Seed: 200. 3000 episodes completed: Mean cumulative reward: 20.156666666666666
Seed: 200. 3600 episodes completed: Mean cumulative reward: 21.105
Seed: 200. 4200 episodes completed: Mean cumulative reward: 20.99
Seed: 200. 4800 episodes completed: Mean cumulative reward: 72.76833333333333
Seed: 200. 5400 episodes completed: Mean cumulative reward: 90.055
Seed: 200. 6000 episodes completed: Mean cumulative reward: 104.295
Seed: 200. 6600 episodes completed: Mean cumulative reward: 261.6766666666667
Seed: 200. 7200 episodes completed: Mean cumulative reward: 289.32166666666666
Seed: 200. 7800 episodes completed: Mean cumulative reward: 339.8333333333333
Seed: 200. 8400 episodes completed: Mean cumulative reward: 275.41333333333336
Seed: 200. 9000 episodes completed: Mean cumulative reward: 207.095
Seed: 200. 9600 episodes completed: Mean cumulative reward: 312.07166666666666
Seed: 200. 10200 episodes completed: Mean cumulative reward: 479.3433333333333
Seed: 200. 10800 episodes completed: Mean cumulative reward: 409.3666666666667
Seed: 200. 11400 episodes completed: Mean cumulative reward: 306.9166666666667
Seed: 200. 12000 episodes completed: Mean cumulative reward: 320.3016666666667
Mean test reward 62.54 +/- std 100.67883789555778
Mean across seeds
600 episodes completed: Mean cumulative reward: 15.188333333333333
1200 episodes completed: Mean cumulative reward: 12.227222222222222
1800 episodes completed: Mean cumulative reward: 28.132222222222225
2400 episodes completed: Mean cumulative reward: 27.167777777777776
3000 episodes completed: Mean cumulative reward: 40.863888888888894
3600 episodes completed: Mean cumulative reward: 37.56444444444445
4200 episodes completed: Mean cumulative reward: 36.185
4800 episodes completed: Mean cumulative reward: 59.68
5400 episodes completed: Mean cumulative reward: 69.87722222222222
6000 episodes completed: Mean cumulative reward: 107.65
6600 episodes completed: Mean cumulative reward: 150.65166666666667
7200 episodes completed: Mean cumulative reward: 193.28777777777776
7800 episodes completed: Mean cumulative reward: 246.70055555555552
8400 episodes completed: Mean cumulative reward: 279.2544444444444
9000 episodes completed: Mean cumulative reward: 271.7955555555555
9600 episodes completed: Mean cumulative reward: 374.04
10200 episodes completed: Mean cumulative reward: 450.2733333333333
10800 episodes completed: Mean cumulative reward: 450.883888888889
11400 episodes completed: Mean cumulative reward: 410.81388888888887
12000 episodes completed: Mean cumulative reward: 422.30611111111114
Best seed
600 episodes completed: Mean cumulative reward: 13.628333333333334
1200 episodes completed: Mean cumulative reward: 11.203333333333333
1800 episodes completed: Mean cumulative reward: 57.78
2400 episodes completed: Mean cumulative reward: 52.778333333333336
3000 episodes completed: Mean cumulative reward: 44.85166666666667
3600 episodes completed: Mean cumulative reward: 42.39666666666667
4200 episodes completed: Mean cumulative reward: 53.04666666666667
4800 episodes completed: Mean cumulative reward: 57.66166666666667
5400 episodes completed: Mean cumulative reward: 64.42333333333333
6000 episodes completed: Mean cumulative reward: 143.79
6600 episodes completed: Mean cumulative reward: 118.92333333333333
7200 episodes completed: Mean cumulative reward: 196.46166666666667
7800 episodes completed: Mean cumulative reward: 283.28
8400 episodes completed: Mean cumulative reward: 438.675
9000 episodes completed: Mean cumulative reward: 442.15166666666664
9600 episodes completed: Mean cumulative reward: 457.555
10200 episodes completed: Mean cumulative reward: 451.0783333333333
10800 episodes completed: Mean cumulative reward: 468.245
11400 episodes completed: Mean cumulative reward: 439.64666666666665
12000 episodes completed: Mean cumulative reward: 458.2816666666667
Mean test reward 500.0 +/- std 0.0
{'env': 'CartPole-v0', 'numdiscreteactions': 8, 'double': True, 'per': True, 'dueling': True, 'rnd': False, 'multistep': None, 'gamma': 0.99, 'alpha': 0.0005, 'alpha_decay_every': 2000, 'alphadecay': 0.95, 'alpha_rnd': 0.001, 'epsilon': 1.0, 'epsilondecay': 0.99, 'minepsilon': 0.2, 'buffersize': 100000, 'batchsize': 128, 'train': True, 'hiddensize': 100, 'activation': 'tanh', 'numseeds': 3, 'numepisodes': 12000, 'numtestepisodes': 100, 'numsteps': 500, 'fititerations': 1, 'update_Qt_after': 20, 'opponent': 'weak', 'curriculum': False, 'save': True, 'savepath': '../saved/', 'savenum': 7, 'test': True, 'testfilename': None, 'plot': True, 'plotpath': '../plots/', 'verbose': False}
Random number: 7
