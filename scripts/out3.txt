Device: cpu
{'env': 'CartPole-v0', 'numdiscreteactions': 8, 'double': True, 'per': False, 'dueling': False, 'rnd': False, 'multistep': None, 'gamma': 0.99, 'alpha': 0.0005, 'alpha_decay_every': 2000, 'alphadecay': 0.95, 'alpha_rnd': 0.001, 'epsilon': 1.0, 'epsilondecay': 0.99, 'minepsilon': 0.2, 'buffersize': 100000, 'batchsize': 128, 'train': True, 'hiddensize': 100, 'activation': 'tanh', 'numseeds': 3, 'numepisodes': 12000, 'numtestepisodes': 100, 'numsteps': 500, 'fititerations': 1, 'update_Qt_after': 20, 'opponent': 'weak', 'curriculum': False, 'save': True, 'savepath': '../saved/', 'savenum': 3, 'test': True, 'testfilename': None, 'plot': True, 'plotpath': '../plots/', 'verbose': False}
/Users/surabhisnath/opt/anaconda3/envs/RL_course/lib/python3.12/site-packages/gymnasium/envs/registration.py:517: DeprecationWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.deprecation(
Config for seed 0:
1.0
Starting seed 1
/Users/surabhisnath/Nextcloud/Documents/PhD/Courses/RL/RL_project/scripts/agent.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  Qtval = self.Qt.doubleQt(s_, torch.tensor(actions_to_use, device=device)).cpu().numpy()
Seed: 0. 600 episodes completed: Mean cumulative reward: 20.238333333333333
Seed: 0. 1200 episodes completed: Mean cumulative reward: 10.88
Seed: 0. 1800 episodes completed: Mean cumulative reward: 24.683333333333334
Seed: 0. 2400 episodes completed: Mean cumulative reward: 58.69166666666667
Seed: 0. 3000 episodes completed: Mean cumulative reward: 61.373333333333335
Seed: 0. 3600 episodes completed: Mean cumulative reward: 48.35333333333333
Seed: 0. 4200 episodes completed: Mean cumulative reward: 59.818333333333335
Seed: 0. 4800 episodes completed: Mean cumulative reward: 66.33333333333333
Seed: 0. 5400 episodes completed: Mean cumulative reward: 70.795
Seed: 0. 6000 episodes completed: Mean cumulative reward: 63.055
Seed: 0. 6600 episodes completed: Mean cumulative reward: 89.87
Seed: 0. 7200 episodes completed: Mean cumulative reward: 94.26666666666667
Seed: 0. 7800 episodes completed: Mean cumulative reward: 123.59166666666667
Seed: 0. 8400 episodes completed: Mean cumulative reward: 173.89833333333334
Seed: 0. 9000 episodes completed: Mean cumulative reward: 187.55
Seed: 0. 9600 episodes completed: Mean cumulative reward: 241.82
Seed: 0. 10200 episodes completed: Mean cumulative reward: 127.775
Seed: 0. 10800 episodes completed: Mean cumulative reward: 142.31666666666666
Seed: 0. 11400 episodes completed: Mean cumulative reward: 188.435
Seed: 0. 12000 episodes completed: Mean cumulative reward: 304.5366666666667
/Users/surabhisnath/opt/anaconda3/envs/RL_course/lib/python3.12/site-packages/gymnasium/envs/registration.py:517: DeprecationWarning: [33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.[0m
  logger.deprecation(
Mean test reward 493.77 +/- std 19.30588252321038
Config for seed 100:
1.0
Starting seed 101
Seed: 100. 600 episodes completed: Mean cumulative reward: 16.751666666666665
Seed: 100. 1200 episodes completed: Mean cumulative reward: 10.551666666666666
Seed: 100. 1800 episodes completed: Mean cumulative reward: 10.43
Seed: 100. 2400 episodes completed: Mean cumulative reward: 10.456666666666667
Seed: 100. 3000 episodes completed: Mean cumulative reward: 10.588333333333333
Seed: 100. 3600 episodes completed: Mean cumulative reward: 10.97
Seed: 100. 4200 episodes completed: Mean cumulative reward: 12.288333333333334
Seed: 100. 4800 episodes completed: Mean cumulative reward: 29.398333333333333
Seed: 100. 5400 episodes completed: Mean cumulative reward: 55.665
Seed: 100. 6000 episodes completed: Mean cumulative reward: 24.571666666666665
Seed: 100. 6600 episodes completed: Mean cumulative reward: 51.42
Seed: 100. 7200 episodes completed: Mean cumulative reward: 155.78833333333333
Seed: 100. 7800 episodes completed: Mean cumulative reward: 188.31333333333333
Seed: 100. 8400 episodes completed: Mean cumulative reward: 223.49
Seed: 100. 9000 episodes completed: Mean cumulative reward: 238.065
Seed: 100. 9600 episodes completed: Mean cumulative reward: 220.44833333333332
Seed: 100. 10200 episodes completed: Mean cumulative reward: 209.915
Seed: 100. 10800 episodes completed: Mean cumulative reward: 179.53833333333333
Seed: 100. 11400 episodes completed: Mean cumulative reward: 154.59666666666666
Seed: 100. 12000 episodes completed: Mean cumulative reward: 182.72
Mean test reward 190.71 +/- std 30.326323549022554
Config for seed 200:
1.0
Starting seed 201
Seed: 200. 600 episodes completed: Mean cumulative reward: 11.966666666666667
Seed: 200. 1200 episodes completed: Mean cumulative reward: 10.653333333333334
Seed: 200. 1800 episodes completed: Mean cumulative reward: 10.698333333333334
Seed: 200. 2400 episodes completed: Mean cumulative reward: 10.451666666666666
Seed: 200. 3000 episodes completed: Mean cumulative reward: 10.581666666666667
Seed: 200. 3600 episodes completed: Mean cumulative reward: 10.936666666666667
Seed: 200. 4200 episodes completed: Mean cumulative reward: 53.475
Seed: 200. 4800 episodes completed: Mean cumulative reward: 65.98166666666667
Seed: 200. 5400 episodes completed: Mean cumulative reward: 82.98166666666667
Seed: 200. 6000 episodes completed: Mean cumulative reward: 114.78333333333333
Seed: 200. 6600 episodes completed: Mean cumulative reward: 108.27666666666667
Seed: 200. 7200 episodes completed: Mean cumulative reward: 93.78333333333333
Seed: 200. 7800 episodes completed: Mean cumulative reward: 108.85166666666667
Seed: 200. 8400 episodes completed: Mean cumulative reward: 121.95
Seed: 200. 9000 episodes completed: Mean cumulative reward: 125.615
Seed: 200. 9600 episodes completed: Mean cumulative reward: 104.26833333333333
Seed: 200. 10200 episodes completed: Mean cumulative reward: 69.67666666666666
Seed: 200. 10800 episodes completed: Mean cumulative reward: 42.69
Seed: 200. 11400 episodes completed: Mean cumulative reward: 40.945
Seed: 200. 12000 episodes completed: Mean cumulative reward: 74.03333333333333
Mean test reward 111.67 +/- std 4.384187495990563
Mean across seeds
600 episodes completed: Mean cumulative reward: 16.31888888888889
1200 episodes completed: Mean cumulative reward: 10.695
1800 episodes completed: Mean cumulative reward: 15.270555555555553
2400 episodes completed: Mean cumulative reward: 26.533333333333335
3000 episodes completed: Mean cumulative reward: 27.51444444444444
3600 episodes completed: Mean cumulative reward: 23.42
4200 episodes completed: Mean cumulative reward: 41.86055555555556
4800 episodes completed: Mean cumulative reward: 53.904444444444444
5400 episodes completed: Mean cumulative reward: 69.81388888888888
6000 episodes completed: Mean cumulative reward: 67.47
6600 episodes completed: Mean cumulative reward: 83.1888888888889
7200 episodes completed: Mean cumulative reward: 114.61277777777778
7800 episodes completed: Mean cumulative reward: 140.2522222222222
8400 episodes completed: Mean cumulative reward: 173.11277777777775
9000 episodes completed: Mean cumulative reward: 183.74333333333334
9600 episodes completed: Mean cumulative reward: 188.84555555555556
10200 episodes completed: Mean cumulative reward: 135.7888888888889
10800 episodes completed: Mean cumulative reward: 121.515
11400 episodes completed: Mean cumulative reward: 127.99222222222224
12000 episodes completed: Mean cumulative reward: 187.09666666666666
Best seed
600 episodes completed: Mean cumulative reward: 20.238333333333333
1200 episodes completed: Mean cumulative reward: 10.88
1800 episodes completed: Mean cumulative reward: 24.683333333333334
2400 episodes completed: Mean cumulative reward: 58.69166666666667
3000 episodes completed: Mean cumulative reward: 61.373333333333335
3600 episodes completed: Mean cumulative reward: 48.35333333333333
4200 episodes completed: Mean cumulative reward: 59.818333333333335
4800 episodes completed: Mean cumulative reward: 66.33333333333333
5400 episodes completed: Mean cumulative reward: 70.795
6000 episodes completed: Mean cumulative reward: 63.055
6600 episodes completed: Mean cumulative reward: 89.87
7200 episodes completed: Mean cumulative reward: 94.26666666666667
7800 episodes completed: Mean cumulative reward: 123.59166666666667
8400 episodes completed: Mean cumulative reward: 173.89833333333334
9000 episodes completed: Mean cumulative reward: 187.55
9600 episodes completed: Mean cumulative reward: 241.82
10200 episodes completed: Mean cumulative reward: 127.775
10800 episodes completed: Mean cumulative reward: 142.31666666666666
11400 episodes completed: Mean cumulative reward: 188.435
12000 episodes completed: Mean cumulative reward: 304.5366666666667
Mean test reward 496.6 +/- std 14.585609346201482
{'env': 'CartPole-v0', 'numdiscreteactions': 8, 'double': True, 'per': False, 'dueling': False, 'rnd': False, 'multistep': None, 'gamma': 0.99, 'alpha': 0.0005, 'alpha_decay_every': 2000, 'alphadecay': 0.95, 'alpha_rnd': 0.001, 'epsilon': 1.0, 'epsilondecay': 0.99, 'minepsilon': 0.2, 'buffersize': 100000, 'batchsize': 128, 'train': True, 'hiddensize': 100, 'activation': 'tanh', 'numseeds': 3, 'numepisodes': 12000, 'numtestepisodes': 100, 'numsteps': 500, 'fititerations': 1, 'update_Qt_after': 20, 'opponent': 'weak', 'curriculum': False, 'save': True, 'savepath': '../saved/', 'savenum': 3, 'test': True, 'testfilename': None, 'plot': True, 'plotpath': '../plots/', 'verbose': False}
Random number: 3
